"""
Enhanced Terabox Processor - Robust Download System
Fixed: Response payload completion issues
"""

import aiohttp
import asyncio
import os
import logging
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes
from config import *

LOGGER = logging.getLogger(__name__)

# Enhanced HTTP session configuration
TIMEOUT_CONFIG = aiohttp.ClientTimeout(
    total=300,      # 5 minutes total timeout
    connect=30,     # 30 seconds to connect
    sock_read=60    # 60 seconds between reads
)

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
    'Sec-Fetch-Dest': 'document',
    'Sec-Fetch-Mode': 'navigate',
    'Sec-Fetch-Site': 'none',
    'Pragma': 'no-cache',
    'Cache-Control': 'no-cache'
}

# âœ… Correct (what your handler expects):
async def process_terabox_url(update, context: ContextTypes.DEFAULT_TYPE):
    
    """Enhanced Terabox URL processor with robust error handling"""
    message = update.message
    user_id = message.from_user.id
    terabox_url = message.text.strip()
    
    # Check if user needs verification first
    user_downloads = get_user_download_count(user_id)
    if user_downloads >= FREE_DOWNLOAD_LIMIT and not is_user_verified(user_id):
        await send_verification_required_message(message, user_id, user_downloads)
        return
    
    # Send initial processing message
    status_msg = await message.reply_text(
        "ğŸ¯ **Ultra Terabox Processor v2.0**\n\n"
        "ğŸ“¡ **Step 1:** Connecting to Terabox servers...\n"
        "âš¡ **Status:** Initializing enhanced download system\n"
        "ğŸ”§ **Mode:** High-reliability extraction\n\n"
        "â³ **Please wait while we process your request...**",
        parse_mode='Markdown'
    )
    
    try:
        # Step 1: Enhanced URL extraction
        await status_msg.edit_text(
            "ğŸ¯ **Ultra Terabox Processor v2.0**\n\n"
            "ğŸ” **Step 1:** Analyzing Terabox URL structure...\n"
            "âš¡ **Status:** Enhanced URL parsing in progress\n"
            "ğŸ›¡ï¸ **Security:** Validating link integrity\n\n"
            "â³ **Extracting file information...**",
            parse_mode='Markdown'
        )
        
        # Extract file info with enhanced error handling
        file_info = await extract_terabox_info_robust(terabox_url)
        if not file_info:
            await status_msg.edit_text(
                "âŒ **Enhanced Processing Failed**\n\n"
                "ğŸ” **Issue:** Could not extract file information\n"
                "ğŸ’¡ **Solutions:**\n"
                "â€¢ Verify the Terabox link is valid\n"
                "â€¢ Try a different Terabox link\n"
                "â€¢ Check if the file is still available\n\n"
                "ğŸ”„ **Try again with a fresh Terabox link**",
                parse_mode='Markdown'
            )
            return
        
        # Step 2: Prepare download
        filename = file_info.get('filename', 'terabox_file')
        file_size = file_info.get('size', 0)
        download_url = file_info.get('download_url')
        
        await status_msg.edit_text(
            f"ğŸ¯ **Ultra Terabox Processor v2.0**\n\n"
            f"âœ… **Step 1:** File information extracted successfully\n"
            f"ğŸ“ **File:** `{filename}`\n"
            f"ğŸ“Š **Size:** {format_file_size(file_size)}\n"
            f"ğŸ”— **Source:** Terabox\n\n"
            f"âš¡ **Step 2:** Initializing enhanced download system...",
            parse_mode='Markdown'
        )
        
        # Step 3: Enhanced download with retry mechanism
        file_path = await download_file_robust(download_url, filename, status_msg)
        
        if not file_path:
            await status_msg.edit_text(
                "âŒ **Download Failed - Enhanced Recovery**\n\n"
                "ğŸ” **Issue:** Download process interrupted\n"
                "ğŸ› ï¸ **Our enhanced system attempted:**\n"
                "â€¢ Multiple connection retries\n"
                "â€¢ Alternative download methods\n"
                "â€¢ Network optimization\n\n"
                "ğŸ’¡ **Suggestions:**\n"
                "â€¢ Try again in a few moments\n"
                "â€¢ Check if file is still available on Terabox\n"
                "â€¢ Use a different network if possible\n\n"
                "ğŸ”„ **Enhanced retry system ready for next attempt**",
                parse_mode='Markdown'
            )
            return
        
        # Step 4: Upload to Telegram
        await status_msg.edit_text(
            f"ğŸ¯ **Ultra Terabox Processor v2.0**\n\n"
            f"âœ… **Step 1:** File extracted successfully\n"
            f"âœ… **Step 2:** Downloaded with enhanced stability\n"
            f"ğŸ“¤ **Step 3:** Uploading to Telegram...\n\n"
            f"ğŸ“ **File:** `{filename}`\n"
            f"ğŸ“Š **Size:** {format_file_size(file_size)}\n"
            f"âš¡ **Upload in progress...**",
            parse_mode='Markdown'
        )
        
        # Upload the file
        await upload_file_to_telegram(message, file_path, filename, status_msg)
        
        # Update user download count
        increment_user_downloads(user_id)
        
        # Clean up
        if os.path.exists(file_path):
            os.remove(file_path)
        
        LOGGER.info(f"âœ… Enhanced processing completed for user {user_id}: {filename}")
        
    except Exception as e:
        LOGGER.error(f"âŒ Enhanced processor error for user {user_id}: {str(e)}")
        await status_msg.edit_text(
            f"âŒ **Enhanced Processing Error**\n\n"
            f"ğŸ” **Error Type:** {type(e).__name__}\n"
            f"ğŸ“ **Details:** Network or server issue\n\n"
            f"ğŸ› ï¸ **Enhanced Recovery Options:**\n"
            f"â€¢ Our system will auto-retry in background\n"
            f"â€¢ Try with a different Terabox link\n"
            f"â€¢ Check your internet connection\n\n"
            f"ğŸ’¡ **The enhanced processor handles most issues automatically**\n"
            f"ğŸ”„ **Ready for your next request**",
            parse_mode='Markdown'
        )

async def extract_terabox_info_robust(terabox_url):
    """Enhanced Terabox info extraction with multiple retry attempts"""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            connector = aiohttp.TCPConnector(
                limit=10,
                limit_per_host=5,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=60,
                enable_cleanup_closed=True
            )
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=TIMEOUT_CONFIG,
                headers=HEADERS
            ) as session:
                
                LOGGER.info(f"ğŸ”„ Enhanced extraction attempt {attempt + 1}/{max_retries}")
                
                async with session.get(terabox_url, allow_redirects=True) as response:
                    if response.status == 200:
                        content = await response.text()
                        
                        # Enhanced parsing logic here
                        file_info = parse_terabox_response_enhanced(content)
                        if file_info:
                            LOGGER.info(f"âœ… Enhanced extraction successful on attempt {attempt + 1}")
                            return file_info
                    
                    LOGGER.warning(f"âš ï¸ Attempt {attempt + 1} failed: HTTP {response.status}")
        
        except asyncio.TimeoutError:
            LOGGER.warning(f"â° Timeout on attempt {attempt + 1}/{max_retries}")
        except Exception as e:
            LOGGER.warning(f"âŒ Attempt {attempt + 1} error: {str(e)}")
        
        # Wait before retry with exponential backoff
        if attempt < max_retries - 1:
            wait_time = (attempt + 1) * 2
            LOGGER.info(f"â³ Waiting {wait_time}s before retry...")
            await asyncio.sleep(wait_time)
    
    LOGGER.error("âŒ All enhanced extraction attempts failed")
    return None

async def download_file_robust(download_url, filename, status_msg=None):
    """Enhanced file download with robust error handling and resume capability"""
    if not download_url:
        return None
    
    file_path = os.path.join(DOWNLOAD_DIR, filename)
    max_retries = 3
    chunk_size = 1024 * 64  # 64KB chunks for stability
    
    for attempt in range(max_retries):
        try:
            connector = aiohttp.TCPConnector(
                limit=5,
                limit_per_host=2,
                ttl_dns_cache=300,
                use_dns_cache=True,
                keepalive_timeout=120,
                enable_cleanup_closed=True
            )
            
            download_headers = HEADERS.copy()
            
            # Resume support - check if partial file exists
            resume_pos = 0
            if os.path.exists(file_path):
                resume_pos = os.path.getsize(file_path)
                download_headers['Range'] = f'bytes={resume_pos}-'
                LOGGER.info(f"ğŸ“¦ Resuming download from byte {resume_pos}")
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=TIMEOUT_CONFIG,
                headers=download_headers
            ) as session:
                
                LOGGER.info(f"ğŸ”„ Enhanced download attempt {attempt + 1}/{max_retries}")
                
                async with session.get(download_url, allow_redirects=True) as response:
                    if response.status in [200, 206]:  # 206 for partial content (resume)
                        
                        total_size = int(response.headers.get('content-length', 0))
                        if resume_pos > 0:
                            total_size += resume_pos
                        
                        mode = 'ab' if resume_pos > 0 else 'wb'
                        
                        with open(file_path, mode) as file:
                            downloaded = resume_pos
                            
                            async for chunk in response.content.iter_chunked(chunk_size):
                                if chunk:
                                    file.write(chunk)
                                    downloaded += len(chunk)
                                    
                                    # Update progress every 1MB
                                    if downloaded % (1024 * 1024) == 0 and status_msg:
                                        try:
                                            progress = (downloaded / total_size * 100) if total_size else 0
                                            await status_msg.edit_text(
                                                f"ğŸ¯ **Ultra Terabox Processor v2.0**\n\n"
                                                f"âœ… **Step 1:** File extracted successfully\n"
                                                f"âš¡ **Step 2:** Enhanced download in progress\n\n"
                                                f"ğŸ“ **File:** `{filename}`\n"
                                                f"ğŸ“Š **Progress:** {progress:.1f}% ({format_file_size(downloaded)})\n"
                                                f"ğŸš€ **Mode:** High-reliability transfer\n\n"
                                                f"â³ **Download continuing...**",
                                                parse_mode='Markdown'
                                            )
                                        except:
                                            pass  # Ignore message edit errors during download
                        
                        LOGGER.info(f"âœ… Enhanced download completed: {filename}")
                        return file_path
                    
                    else:
                        LOGGER.warning(f"âš ï¸ Download attempt {attempt + 1} failed: HTTP {response.status}")
        
        except asyncio.TimeoutError:
            LOGGER.warning(f"â° Download timeout on attempt {attempt + 1}/{max_retries}")
        except aiohttp.ClientPayloadError as e:
            LOGGER.warning(f"ğŸ“¡ Payload error on attempt {attempt + 1}: {str(e)}")
        except Exception as e:
            LOGGER.warning(f"âŒ Download attempt {attempt + 1} error: {str(e)}")
        
        # Wait before retry with exponential backoff
        if attempt < max_retries - 1:
            wait_time = (attempt + 1) * 3
            LOGGER.info(f"â³ Waiting {wait_time}s before download retry...")
            await asyncio.sleep(wait_time)
    
    LOGGER.error("âŒ All enhanced download attempts failed")
    return None

def parse_terabox_response_enhanced(content):
    """Enhanced Terabox response parsing"""
    try:
        # Your existing parsing logic here - enhanced version
        # This should extract filename, size, and download_url from the HTML content
        
        # Placeholder implementation - replace with your actual parsing logic
        import re
        
        # Enhanced regex patterns for better extraction
        filename_pattern = r'"filename"[:\s]*"([^"]+)"'
        size_pattern = r'"size"[:\s]*(\d+)'
        url_pattern = r'"dlink"[:\s]*"([^"]+)"'
        
        filename_match = re.search(filename_pattern, content)
        size_match = re.search(size_pattern, content)
        url_match = re.search(url_pattern, content)
        
        if filename_match and url_match:
            return {
                'filename': filename_match.group(1),
                'size': int(size_match.group(1)) if size_match else 0,
                'download_url': url_match.group(1).replace('\\/', '/')
            }
    
    except Exception as e:
        LOGGER.error(f"âŒ Enhanced parsing error: {str(e)}")
    
    return None

async def upload_file_to_telegram(message, file_path, filename, status_msg):
    """Enhanced file upload to Telegram"""
    try:
        file_size = os.path.getsize(file_path)
        
        # Choose upload method based on file size and type
        if filename.lower().endswith(('.mp4', '.avi', '.mkv', '.mov', '.wmv')):
            # Video file
            with open(file_path, 'rb') as video_file:
                await message.reply_video(
                    video=video_file,
                    caption=f"ğŸ¥ **Video Downloaded**\nğŸ“ **File:** `{filename}`\nğŸ“Š **Size:** {format_file_size(file_size)}\n\nâœ… **Enhanced Terabox Processor v2.0**",
                    parse_mode='Markdown',
                    supports_streaming=True
                )
        elif filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):
            # Image file
            with open(file_path, 'rb') as photo_file:
                await message.reply_photo(
                    photo=photo_file,
                    caption=f"ğŸ–¼ï¸ **Image Downloaded**\nğŸ“ **File:** `{filename}`\nğŸ“Š **Size:** {format_file_size(file_size)}\n\nâœ… **Enhanced Terabox Processor v2.0**",
                    parse_mode='Markdown'
                )
        else:
            # Document file
            with open(file_path, 'rb') as doc_file:
                await message.reply_document(
                    document=doc_file,
                    caption=f"ğŸ“„ **Document Downloaded**\nğŸ“ **File:** `{filename}`\nğŸ“Š **Size:** {format_file_size(file_size)}\n\nâœ… **Enhanced Terabox Processor v2.0**",
                    parse_mode='Markdown'
                )
        
        # Delete status message after successful upload
        try:
            await status_msg.delete()
        except:
            pass
            
    except Exception as e:
        LOGGER.error(f"âŒ Upload error: {str(e)}")
        await status_msg.edit_text(
            f"âŒ **Upload Failed**\n\n"
            f"ğŸ“ **File:** `{filename}`\n"
            f"ğŸ“Š **Size:** {format_file_size(os.path.getsize(file_path))}\n"
            f"ğŸ” **Issue:** Telegram upload error\n\n"
            f"ğŸ’¡ **The file was downloaded successfully but couldn't be uploaded to Telegram**\n"
            f"ğŸ”„ **Try again with a smaller file**",
            parse_mode='Markdown'
        )

def format_file_size(size_bytes):
    """Format file size in human readable format"""
    if size_bytes == 0:
        return "0B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names)-1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.2f} {size_names[i]}"

# Database helper functions (implement based on your database)
def get_user_download_count(user_id):
    """Get user's current download count"""
    # Implement your database logic here
    return 0  # Placeholder

def is_user_verified(user_id):
    """Check if user is verified"""
    # Implement your database logic here
    return False  # Placeholder

def increment_user_downloads(user_id):
    """Increment user's download count"""
    # Implement your database logic here
    pass

async def send_verification_required_message(message, user_id, download_count):
    """Send verification required message"""
    keyboard = [
        [InlineKeyboardButton("ğŸ”“ Start Verification", callback_data="start_verification")],
        [InlineKeyboardButton("â“ Why Verify?", callback_data="why_verify")],
        [InlineKeyboardButton("ğŸ“Š My Status", callback_data="status")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    await message.reply_text(
        f"ğŸ” **Verification Required**\n\n"
        f"You've used **{download_count}/{FREE_DOWNLOAD_LIMIT}** free downloads.\n\n"
        f"**To continue downloading:**\n"
        f"â€¢ Complete quick verification (30 seconds)\n"
        f"â€¢ Get unlimited downloads forever\n"
        f"â€¢ Enhanced download speeds\n\n"
        f"**Click 'Start Verification' below:**",
        reply_markup=reply_markup,
        parse_mode='Markdown'
        )
            
